{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling- Variable Selection\n",
    "- Robert Shaw, Sean Coleman, Spencer Evans, Daniel Alpert\n",
    "- CS109a Project- Data Driven March Madness\n",
    "\n",
    "---\n",
    "\n",
    "In this file, we perform variable selection for our logistic regression model of head to head games. To do this, we will use a combination of subset selection methods and regularization methods. Further, we will consider looking at scoring differential and using lasso regression as a variable selection method.\n",
    "\n",
    "\n",
    "Further, we will also look at random forest, lda, and svc to see if there is a major improvement in our model's accuracy. However, we like the interpretaion available using logistic regression, so unless we see a major improvement in accuracy we will stick with logistic regession.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import march_madness_classes as mmc\n",
    "import march_madness_games as mmg\n",
    "import march_madness_models as mmm\n",
    "import march_madness_train_and_tune as mmtt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression as LogReg\n",
    "from sklearn.linear_model import Lasso as Lasso\n",
    "from sklearn.ensemble import RandomForestClassifier as random_forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Load Our Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in the dataset\n",
    "seeds = pd.read_csv(\"datasets/kaggle_data/TourneySeeds.csv\")\n",
    "slots = pd.read_csv(\"datasets/kaggle_data/TourneySlots.csv\")\n",
    "games = pd.read_csv(\"datasets/kaggle_data/TourneyCompactResults.csv\")\n",
    "\n",
    "seeds_arr = mmg.filter_into_seasons(seeds)\n",
    "slots_arr = mmg.filter_into_seasons(slots)\n",
    "games_arr = mmg.filter_into_seasons(games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# extract predictors\n",
    "markov          = pd.read_csv(\"datasets/our_data/stationary\", index_col=0)\n",
    "rpi             = pd.read_csv(\"datasets/our_data/rpi\", index_col=0)\n",
    "weighted_wins   = pd.read_csv(\"datasets/our_data/weighted_wins\", index_col=0)\n",
    "consistency     = pd.read_csv(\"datasets/our_data/consistency\", index_col=0)\n",
    "dominance       = pd.read_csv(\"datasets/our_data/dominance\", index_col=0)\n",
    "bad_losses      = pd.read_csv(\"datasets/our_data/bad_losses\", index_col=0)\n",
    "tough_wins      = pd.read_csv(\"datasets/our_data/tough_wins\", index_col=0)\n",
    "close_wins      = pd.read_csv(\"datasets/our_data/close_wins\",index_col=0)\n",
    "close_wins_perc = pd.read_csv(\"datasets/our_data/close_wins_perc\", index_col=0)\n",
    "momentum        = pd.read_csv(\"datasets/our_data/momentum\", index_col=0)\n",
    "past_resul      = pd.read_csv(\"datasets/our_data/past_results\", index_col=0)\n",
    "def_eff         = pd.read_csv(\"datasets/our_data/def_eff\", index_col=0)\n",
    "off_eff         = pd.read_csv(\"datasets/our_data/off_eff\", index_col=0)\n",
    "tempo           = pd.read_csv(\"datasets/our_data/tempo\", index_col=0)\n",
    "win_ratio       = pd.read_csv(\"datasets/our_data/win_ratio\", index_col=0)\n",
    "wins            = pd.read_csv(\"datasets/our_data/team_summary_data/regular_season_wins\", index_col=0)\n",
    "losses          = pd.read_csv(\"datasets/our_data/team_summary_data/regular_season_loss_matrix\", index_col=0)\n",
    "luck            = pd.read_csv(\"datasets/our_data/luck\", index_col=0)\n",
    "\n",
    "# seeds\n",
    "seed_matrix_df  = pd.read_csv(\"datasets/our_data/team_summary_data/seeds_matrix\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'march_madness_games' from 'march_madness_games.py'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(mmg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get data into correct format\n",
    "predictor_names = [\"min_index_id\", \n",
    "                   \"max_index_id\", \n",
    "                   \"markov\",\n",
    "                   \"rpi\",\n",
    "                   \"weighted_wins\",\n",
    "                   \"consistency\",\n",
    "                   \"dominance\", \n",
    "                   \"bad_losses\", \n",
    "                   \"tough_wins\", \n",
    "                   \"close_wins\", \n",
    "                   \"close_wins_perc\", \n",
    "                   \"momentum\",\n",
    "                   \"past_resul\",\n",
    "                   \"def_eff\",\n",
    "                   \"off_eff\",\n",
    "                   \"tempo\",\n",
    "                   \"win ratio\",\n",
    "                   \"wins\",\n",
    "                   \"losses\",\n",
    "                   \"luck\"] \n",
    "\n",
    "# package the predictors into an array\n",
    "predictor_dfs = [markov, \n",
    "                 rpi,\n",
    "                 weighted_wins,  \n",
    "                 consistency,\n",
    "                 dominance, \n",
    "                 bad_losses, \n",
    "                 tough_wins, \n",
    "                 close_wins, \n",
    "                 close_wins_perc, \n",
    "                 momentum,\n",
    "                 past_resul,\n",
    "                 def_eff,\n",
    "                 off_eff,\n",
    "                 tempo,\n",
    "                 win_ratio,\n",
    "                 wins,\n",
    "                 losses,\n",
    "                 luck] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred, resp = mmg.generate_multiple_years_of_games(range(2003, 2016), \n",
    "                                                  seeds_arr, \n",
    "                                                  slots_arr, \n",
    "                                                  games_arr, \n",
    "                                                  predictor_names,\n",
    "                                                  predictor_dfs,\n",
    "                                                  scoring_dif = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_index_id</th>\n",
       "      <th>max_index_id</th>\n",
       "      <th>markov</th>\n",
       "      <th>rpi</th>\n",
       "      <th>weighted_wins</th>\n",
       "      <th>consistency</th>\n",
       "      <th>dominance</th>\n",
       "      <th>bad_losses</th>\n",
       "      <th>tough_wins</th>\n",
       "      <th>close_wins</th>\n",
       "      <th>close_wins_perc</th>\n",
       "      <th>momentum</th>\n",
       "      <th>past_resul</th>\n",
       "      <th>def_eff</th>\n",
       "      <th>off_eff</th>\n",
       "      <th>tempo</th>\n",
       "      <th>win ratio</th>\n",
       "      <th>wins</th>\n",
       "      <th>luck</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1328.0</td>\n",
       "      <td>1354.0</td>\n",
       "      <td>0.004267</td>\n",
       "      <td>0.147791</td>\n",
       "      <td>1.438690</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.027911</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.061449</td>\n",
       "      <td>0.098682</td>\n",
       "      <td>-242.600</td>\n",
       "      <td>0.312454</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.687546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1190.0</td>\n",
       "      <td>1448.0</td>\n",
       "      <td>-0.003134</td>\n",
       "      <td>-0.099574</td>\n",
       "      <td>-0.922222</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.011056</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.031186</td>\n",
       "      <td>-0.093820</td>\n",
       "      <td>67.550</td>\n",
       "      <td>-0.265337</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-6.734663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1264.0</td>\n",
       "      <td>1393.0</td>\n",
       "      <td>-0.001668</td>\n",
       "      <td>-0.060741</td>\n",
       "      <td>-1.209524</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.371429</td>\n",
       "      <td>-0.027433</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.024369</td>\n",
       "      <td>-0.040364</td>\n",
       "      <td>-27.200</td>\n",
       "      <td>-0.033941</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.966059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1122.0</td>\n",
       "      <td>1257.0</td>\n",
       "      <td>-0.003825</td>\n",
       "      <td>-0.074778</td>\n",
       "      <td>-1.672619</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.317460</td>\n",
       "      <td>-0.005877</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058379</td>\n",
       "      <td>-0.098145</td>\n",
       "      <td>-349.875</td>\n",
       "      <td>-0.303111</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-3.696889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1139.0</td>\n",
       "      <td>1280.0</td>\n",
       "      <td>-0.001750</td>\n",
       "      <td>-0.022623</td>\n",
       "      <td>-1.723077</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>-0.006086</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.109495</td>\n",
       "      <td>0.077419</td>\n",
       "      <td>-242.275</td>\n",
       "      <td>-0.058307</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.058307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   min_index_id  max_index_id    markov       rpi  weighted_wins  consistency  \\\n",
       "0        1328.0        1354.0  0.004267  0.147791       1.438690         -4.0   \n",
       "1        1190.0        1448.0 -0.003134 -0.099574      -0.922222          5.0   \n",
       "2        1264.0        1393.0 -0.001668 -0.060741      -1.209524          1.0   \n",
       "3        1122.0        1257.0 -0.003825 -0.074778      -1.672619          1.0   \n",
       "4        1139.0        1280.0 -0.001750 -0.022623      -1.723077         -4.0   \n",
       "\n",
       "   dominance  bad_losses  tough_wins  close_wins  close_wins_perc  momentum  \\\n",
       "0        4.0        -8.0         3.0         1.0         0.166667  0.027911   \n",
       "1       -7.0         8.0        -2.0         2.0         0.000000 -0.011056   \n",
       "2       -1.0         4.0        -2.0        -1.0        -0.371429 -0.027433   \n",
       "3       -4.0         4.0         0.0         4.0         0.317460 -0.005877   \n",
       "4        3.0        -2.0        -3.0         4.0         0.375000 -0.006086   \n",
       "\n",
       "   past_resul   def_eff   off_eff    tempo  win ratio  wins      luck  \n",
       "0         4.0 -0.061449  0.098682 -242.600   0.312454   4.0  3.687546  \n",
       "1        -1.0  0.031186 -0.093820   67.550  -0.265337  -7.0 -6.734663  \n",
       "2        -1.0 -0.024369 -0.040364  -27.200  -0.033941  -1.0 -0.966059  \n",
       "3         0.0  0.058379 -0.098145 -349.875  -0.303111  -4.0 -3.696889  \n",
       "4         0.0  0.109495  0.077419 -242.275  -0.058307   3.0  3.058307  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_index_win</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   min_index_win\n",
       "0            1.0\n",
       "1            0.0\n",
       "2            0.0\n",
       "3            0.0\n",
       "4            1.0"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2) Train Test Split\n",
    "\n",
    "For our train test splits, we will be using a \"window\" approach. For each year, we will build a model based on the previous 3 years. This will allow us to avoid issues about the idea that the games from year to year are a dependent time series, and will prevent us from over fitting to a specific year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_test_arr = []\n",
    "\n",
    "window   = 3\n",
    "min_year = 2006\n",
    "max_year = 2014\n",
    "\n",
    "year_range = range(min_year, max_year)\n",
    "\n",
    "# generate our train test split for each year\n",
    "for year in year_range:\n",
    "    # do the split for the current year\n",
    "    train_test_tuple = mmtt.train_test_split(window, \n",
    "                                             year, \n",
    "                                             seeds_arr, \n",
    "                                             slots_arr, \n",
    "                                             games_arr, \n",
    "                                             predictor_names, \n",
    "                                             predictor_dfs)\n",
    "    \n",
    "    # add to our array\n",
    "    train_test_arr.append(train_test_tuple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "### 3) Variable Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try a few methods: \n",
    "\n",
    "- Forward Step Wise with Logistic Regression\n",
    "- Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# runs logisitic model on each year\n",
    "def run_logistic_model (train_test_arr, variables, c=1, max_year=2014, min_year=2006, print_res=True):\n",
    "    # high regularization\n",
    "\n",
    "    # buffer for scores\n",
    "    scores = np.zeros(max_year - min_year)\n",
    "    coef_arr = np.zeros((scores.shape[0], len(variables)))\n",
    "\n",
    "    # iterate years\n",
    "    for year in year_range:\n",
    "        # get train data\n",
    "        train_x = train_test_arr[year - min_year][0][variables]\n",
    "        train_y = train_test_arr[year - min_year][1].values[:, 0]\n",
    "\n",
    "        # get cross validation set\n",
    "        cross_x = train_test_arr[year - min_year][2][variables]\n",
    "        cross_y = train_test_arr[year - min_year][3].values[:, 0]\n",
    "\n",
    "        # scaling\n",
    "        scaler = StandardScaler().fit(train_x)\n",
    "        scaled_train_x = scaler.transform(train_x)\n",
    "        scaled_cross_x = scaler.transform(cross_x)\n",
    "\n",
    "        # init model\n",
    "        model = LogReg(C=c)\n",
    "\n",
    "        # fit model\n",
    "        model.fit(scaled_train_x, train_y)\n",
    "\n",
    "        # get coefs\n",
    "        coef_arr[year - min_year, :] = model.coef_[0]\n",
    "\n",
    "        # score model\n",
    "        scores[year - min_year] = model.score(scaled_cross_x, cross_y)\n",
    "\n",
    "    # results \n",
    "    mean_coefs = np.average(coef_arr, axis=0)\n",
    "    coef_series = pd.Series(mean_coefs, index=variables)\n",
    "\n",
    "    if print_res:\n",
    "        print \"Average Beta:\"\n",
    "        print coef_series.sort_values(ascending=False)\n",
    "    \n",
    "    # return the average score\n",
    "    return np.average(scores), coef_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# runs logisitic model on each year\n",
    "def run_random_forest_model (train_test_arr, variables, max_year=2014, min_year=2006):\n",
    "    # high regularization\n",
    "    c = 1\n",
    "\n",
    "    # buffer for scores\n",
    "    scores = np.zeros(max_year - min_year)\n",
    "    coef_arr = np.zeros((scores.shape[0], len(variables)))\n",
    "\n",
    "    # iterate years\n",
    "    for year in year_range:\n",
    "        # get train data\n",
    "        train_x = train_test_arr[year - min_year][0][variables]\n",
    "        train_y = train_test_arr[year - min_year][1].values[:, 0]\n",
    "\n",
    "        # get cross validation set\n",
    "        cross_x = train_test_arr[year - min_year][2][variables]\n",
    "        cross_y = train_test_arr[year - min_year][3].values[:, 0]\n",
    "\n",
    "        # scaling\n",
    "        scaler = StandardScaler().fit(train_x)\n",
    "        scaled_train_x = scaler.transform(train_x)\n",
    "        scaled_cross_x = scaler.transform(cross_x)\n",
    "\n",
    "        # init model\n",
    "        model = random_forest(n_estimators = 100, max_depth=2)\n",
    "\n",
    "        # fit model\n",
    "        model.fit(scaled_train_x, train_y)\n",
    "\n",
    "        # get coefs\n",
    "        coef_arr[year - min_year, :] = model.feature_importances_\n",
    "\n",
    "        # score model\n",
    "        scores[year - min_year] = model.score(scaled_cross_x, cross_y)\n",
    "\n",
    "    # results \n",
    "    mean_coefs = np.average(coef_arr, axis=0)\n",
    "    coef_series = pd.Series(mean_coefs, index=variables)\n",
    "\n",
    "    print \"Average Beta:\"\n",
    "    print coef_series.sort_values(ascending=False)\n",
    "    \n",
    "    # return the average score\n",
    "    return np.average(scores), coef_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# runs logisitic model on each year\n",
    "def run_lasso_model (train_test_arr, variables, alpha, max_year=2014, min_year=2006, print_res=True):\n",
    "    # buffer for scores\n",
    "    scores = np.zeros(max_year - min_year)\n",
    "    coef_arr = np.zeros((scores.shape[0], len(variables)))\n",
    "\n",
    "    # iterate years\n",
    "    for year in year_range:\n",
    "        # get train data\n",
    "        train_x = train_test_arr[year - min_year][0][variables]\n",
    "        train_y = train_test_arr[year - min_year][1].values[:, 0]\n",
    "\n",
    "        # get cross validation set\n",
    "        cross_x = train_test_arr[year - min_year][2][variables]\n",
    "        cross_y = train_test_arr[year - min_year][3].values[:, 0]\n",
    "\n",
    "        # scaling\n",
    "        scaler = StandardScaler().fit(train_x)\n",
    "        scaled_train_x = scaler.transform(train_x)\n",
    "        scaled_cross_x = scaler.transform(cross_x)\n",
    "\n",
    "        # init model\n",
    "        model = Lasso(alpha=alpha)\n",
    "\n",
    "        # fit model\n",
    "        model.fit(scaled_train_x, train_y)\n",
    "\n",
    "        # get coefs\n",
    "        coef_arr[year - min_year, :] = model.coef_\n",
    "\n",
    "        # score model\n",
    "        scores[year - min_year] = model.score(scaled_cross_x, cross_y)\n",
    "\n",
    "    # results \n",
    "    mean_coefs = np.average(coef_arr, axis=0)\n",
    "    coef_series = pd.Series(mean_coefs, index=variables)\n",
    "\n",
    "    if print_res:\n",
    "        print \"Average Beta:\"\n",
    "        print coef_series.sort_values(ascending=False)\n",
    "    \n",
    "    # return the average score\n",
    "    return np.average(scores), coef_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Backwards Stepwise Logistic\n",
    "\n",
    "- Since all of our variables are standardized, we can compare the coefficients one-to-one in order to see which are more important. We will remove one at a time, picking the lowest abs(beta) in each step. Once we have tried models with all numbers of predictors (1 to 14), we will simply choose the model with the maximum cross validation score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Beta:\n",
      "markov             0.835301\n",
      "rpi                0.564075\n",
      "momentum           0.295006\n",
      "off_eff            0.160792\n",
      "luck               0.068955\n",
      "losses             0.068442\n",
      "consistency        0.068442\n",
      "dominance          0.067438\n",
      "wins               0.067438\n",
      "tough_wins         0.013625\n",
      "win ratio          0.004624\n",
      "close_wins_perc   -0.022888\n",
      "close_wins        -0.100854\n",
      "tempo             -0.117812\n",
      "def_eff           -0.137567\n",
      "past_resul        -0.178838\n",
      "weighted_wins     -0.239996\n",
      "bad_losses        -0.402662\n",
      "dtype: float64\n",
      "\n",
      "Avg Accuracy : 0.688492063492\n",
      "\n",
      "Min Predictor: win ratio\n"
     ]
    }
   ],
   "source": [
    "# list of the variables we care about\n",
    "variables = predictor_names[2:]\n",
    "\n",
    "# array of accuracies\n",
    "accuracy_arr = np.zeros(len(variables))\n",
    "\n",
    "# print with current set of variables\n",
    "accuracy_arr[0], coef_series = run_logistic_model(train_test_arr, variables)\n",
    "\n",
    "# minimum absolute value beta\n",
    "min_abs_x = coef_series.abs().sort_values().index[0]\n",
    "\n",
    "print \"\\nAvg Accuracy : {}\".format(accuracy_arr[0])\n",
    "print \"\\nMin Predictor: {}\".format(min_abs_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Beta:\n",
      "markov             0.836934\n",
      "rpi                0.564859\n",
      "momentum           0.294612\n",
      "off_eff            0.167185\n",
      "luck               0.067656\n",
      "dominance          0.066964\n",
      "wins               0.066964\n",
      "losses             0.066830\n",
      "consistency        0.066830\n",
      "tough_wins         0.009523\n",
      "close_wins_perc   -0.023386\n",
      "close_wins        -0.100343\n",
      "tempo             -0.115292\n",
      "def_eff           -0.139813\n",
      "past_resul        -0.175708\n",
      "weighted_wins     -0.239589\n",
      "bad_losses        -0.402061\n",
      "dtype: float64\n",
      "\n",
      "Avg Accuracy : 0.690476190476\n",
      "\n",
      "Min Predictor: tough_wins\n"
     ]
    }
   ],
   "source": [
    "variables.remove(min_abs_x)\n",
    "i = 1\n",
    "\n",
    "# print with current set of variables\n",
    "accuracy_arr[i], coef_series = run_logistic_model(train_test_arr, variables)\n",
    "\n",
    "# minimum absolute value beta\n",
    "min_abs_x = coef_series.abs().sort_values().index[0]\n",
    "\n",
    "print \"\\nAvg Accuracy : {}\".format(accuracy_arr[i])\n",
    "print \"\\nMin Predictor: {}\".format(min_abs_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Beta:\n",
      "markov             0.811013\n",
      "rpi                0.567666\n",
      "momentum           0.287956\n",
      "off_eff            0.148186\n",
      "luck               0.072703\n",
      "wins               0.072658\n",
      "dominance          0.072658\n",
      "losses             0.065790\n",
      "consistency        0.065790\n",
      "close_wins_perc   -0.009305\n",
      "close_wins        -0.111646\n",
      "def_eff           -0.123289\n",
      "tempo             -0.124044\n",
      "past_resul        -0.154570\n",
      "weighted_wins     -0.219354\n",
      "bad_losses        -0.393630\n",
      "dtype: float64\n",
      "\n",
      "Avg Accuracy : 0.698412698413\n",
      "\n",
      "Min Predictor: close_wins_perc\n"
     ]
    }
   ],
   "source": [
    "variables.remove(min_abs_x)\n",
    "i = 2\n",
    "\n",
    "# print with current set of variables\n",
    "accuracy_arr[i], coef_series = run_logistic_model(train_test_arr, variables)\n",
    "\n",
    "# minimum absolute value beta\n",
    "min_abs_x = coef_series.abs().sort_values().index[0]\n",
    "\n",
    "print \"\\nAvg Accuracy : {}\".format(accuracy_arr[i])\n",
    "print \"\\nMin Predictor: {}\".format(min_abs_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Beta:\n",
      "markov           0.746489\n",
      "rpi              0.569686\n",
      "momentum         0.311733\n",
      "off_eff          0.147271\n",
      "wins             0.080103\n",
      "dominance        0.080103\n",
      "losses           0.077506\n",
      "consistency      0.077506\n",
      "luck             0.077165\n",
      "past_resul      -0.126679\n",
      "close_wins      -0.126821\n",
      "def_eff         -0.129177\n",
      "tempo           -0.136741\n",
      "weighted_wins   -0.215174\n",
      "bad_losses      -0.392537\n",
      "dtype: float64\n",
      "\n",
      "Avg Accuracy : 0.702380952381\n",
      "\n",
      "Min Predictor: luck\n"
     ]
    }
   ],
   "source": [
    "variables.remove(min_abs_x)\n",
    "i = 3\n",
    "\n",
    "# print with current set of variables\n",
    "accuracy_arr[i], coef_series = run_logistic_model(train_test_arr, variables)\n",
    "\n",
    "# minimum absolute value beta\n",
    "min_abs_x = coef_series.abs().sort_values().index[0]\n",
    "\n",
    "print \"\\nAvg Accuracy : {}\".format(accuracy_arr[i])\n",
    "print \"\\nMin Predictor: {}\".format(min_abs_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Beta:\n",
      "markov           0.747012\n",
      "rpi              0.570645\n",
      "momentum         0.313457\n",
      "off_eff          0.147865\n",
      "wins             0.110353\n",
      "dominance        0.110353\n",
      "losses           0.071717\n",
      "consistency      0.071717\n",
      "close_wins      -0.124954\n",
      "past_resul      -0.127171\n",
      "def_eff         -0.130495\n",
      "tempo           -0.133471\n",
      "weighted_wins   -0.216190\n",
      "bad_losses      -0.392366\n",
      "dtype: float64\n",
      "\n",
      "Avg Accuracy : 0.700396825397\n",
      "\n",
      "Min Predictor: consistency\n"
     ]
    }
   ],
   "source": [
    "variables.remove(min_abs_x)\n",
    "i = 4\n",
    "\n",
    "# print with current set of variables\n",
    "accuracy_arr[i], coef_series = run_logistic_model(train_test_arr, variables)\n",
    "\n",
    "# minimum absolute value beta\n",
    "min_abs_x = coef_series.abs().sort_values().index[0]\n",
    "\n",
    "print \"\\nAvg Accuracy : {}\".format(accuracy_arr[i])\n",
    "print \"\\nMin Predictor: {}\".format(min_abs_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Beta:\n",
      "markov           0.750641\n",
      "rpi              0.568232\n",
      "momentum         0.313453\n",
      "off_eff          0.144412\n",
      "losses           0.127200\n",
      "wins             0.103947\n",
      "dominance        0.103947\n",
      "close_wins      -0.124893\n",
      "past_resul      -0.127338\n",
      "def_eff         -0.127924\n",
      "tempo           -0.129393\n",
      "weighted_wins   -0.215402\n",
      "bad_losses      -0.390121\n",
      "dtype: float64\n",
      "\n",
      "Avg Accuracy : 0.700396825397\n",
      "\n",
      "Min Predictor: dominance\n"
     ]
    }
   ],
   "source": [
    "variables.remove(min_abs_x)\n",
    "i = 5\n",
    "\n",
    "# print with current set of variables\n",
    "accuracy_arr[i], coef_series = run_logistic_model(train_test_arr, variables)\n",
    "\n",
    "# minimum absolute value beta\n",
    "min_abs_x = coef_series.abs().sort_values().index[0]\n",
    "\n",
    "print \"\\nAvg Accuracy : {}\".format(accuracy_arr[i])\n",
    "print \"\\nMin Predictor: {}\".format(min_abs_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Beta:\n",
      "markov           0.751498\n",
      "rpi              0.570891\n",
      "momentum         0.316712\n",
      "wins             0.171414\n",
      "off_eff          0.148745\n",
      "losses           0.105170\n",
      "close_wins      -0.121336\n",
      "tempo           -0.123129\n",
      "past_resul      -0.128408\n",
      "def_eff         -0.133399\n",
      "weighted_wins   -0.217460\n",
      "bad_losses      -0.390213\n",
      "dtype: float64\n",
      "\n",
      "Avg Accuracy : 0.708333333333\n",
      "\n",
      "Min Predictor: losses\n"
     ]
    }
   ],
   "source": [
    "variables.remove(min_abs_x)\n",
    "i = 6\n",
    "\n",
    "# print with current set of variables\n",
    "accuracy_arr[i], coef_series = run_logistic_model(train_test_arr, variables)\n",
    "\n",
    "# minimum absolute value beta\n",
    "min_abs_x = coef_series.abs().sort_values().index[0]\n",
    "\n",
    "print \"\\nAvg Accuracy : {}\".format(accuracy_arr[i])\n",
    "print \"\\nMin Predictor: {}\".format(min_abs_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Beta:\n",
      "markov           0.775962\n",
      "rpi              0.556440\n",
      "momentum         0.316272\n",
      "off_eff          0.123989\n",
      "wins             0.094678\n",
      "tempo           -0.096500\n",
      "def_eff         -0.115350\n",
      "close_wins      -0.122114\n",
      "past_resul      -0.128763\n",
      "weighted_wins   -0.212245\n",
      "bad_losses      -0.373213\n",
      "dtype: float64\n",
      "\n",
      "Avg Accuracy : 0.710317460317\n",
      "\n",
      "Min Predictor: wins\n"
     ]
    }
   ],
   "source": [
    "variables.remove(min_abs_x)\n",
    "i = 7\n",
    "\n",
    "# print with current set of variables\n",
    "accuracy_arr[i], coef_series = run_logistic_model(train_test_arr, variables)\n",
    "\n",
    "# minimum absolute value beta\n",
    "min_abs_x = coef_series.abs().sort_values().index[0]\n",
    "\n",
    "print \"\\nAvg Accuracy : {}\".format(accuracy_arr[i])\n",
    "print \"\\nMin Predictor: {}\".format(min_abs_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Beta:\n",
      "markov           0.731109\n",
      "rpi              0.623834\n",
      "momentum         0.319433\n",
      "off_eff          0.179899\n",
      "tempo           -0.089422\n",
      "close_wins      -0.099887\n",
      "past_resul      -0.126730\n",
      "def_eff         -0.174728\n",
      "weighted_wins   -0.220403\n",
      "bad_losses      -0.357551\n",
      "dtype: float64\n",
      "\n",
      "Avg Accuracy : 0.71626984127\n",
      "\n",
      "Min Predictor: tempo\n"
     ]
    }
   ],
   "source": [
    "variables.remove(min_abs_x)\n",
    "i = 8\n",
    "\n",
    "# print with current set of variables\n",
    "accuracy_arr[i], coef_series = run_logistic_model(train_test_arr, variables)\n",
    "\n",
    "# minimum absolute value beta\n",
    "min_abs_x = coef_series.abs().sort_values().index[0]\n",
    "\n",
    "print \"\\nAvg Accuracy : {}\".format(accuracy_arr[i])\n",
    "print \"\\nMin Predictor: {}\".format(min_abs_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Beta:\n",
      "markov           0.663088\n",
      "rpi              0.618914\n",
      "momentum         0.298188\n",
      "off_eff          0.188059\n",
      "close_wins      -0.102235\n",
      "past_resul      -0.124982\n",
      "def_eff         -0.187764\n",
      "weighted_wins   -0.213885\n",
      "bad_losses      -0.373071\n",
      "dtype: float64\n",
      "\n",
      "Avg Accuracy : 0.708333333333\n",
      "\n",
      "Min Predictor: close_wins\n"
     ]
    }
   ],
   "source": [
    "variables.remove(min_abs_x)\n",
    "i = 9\n",
    "\n",
    "# print with current set of variables\n",
    "accuracy_arr[i], coef_series = run_logistic_model(train_test_arr, variables)\n",
    "\n",
    "# minimum absolute value beta\n",
    "min_abs_x = coef_series.abs().sort_values().index[0]\n",
    "\n",
    "print \"\\nAvg Accuracy : {}\".format(accuracy_arr[i])\n",
    "print \"\\nMin Predictor: {}\".format(min_abs_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Beta:\n",
      "markov           0.705238\n",
      "rpi              0.596071\n",
      "momentum         0.250743\n",
      "off_eff          0.217637\n",
      "past_resul      -0.115820\n",
      "weighted_wins   -0.209006\n",
      "def_eff         -0.211680\n",
      "bad_losses      -0.347275\n",
      "dtype: float64\n",
      "\n",
      "Avg Accuracy : 0.698412698413\n",
      "\n",
      "Min Predictor: past_resul\n"
     ]
    }
   ],
   "source": [
    "variables.remove(min_abs_x)\n",
    "i = 10\n",
    "\n",
    "# print with current set of variables\n",
    "accuracy_arr[i], coef_series = run_logistic_model(train_test_arr, variables)\n",
    "\n",
    "# minimum absolute value beta\n",
    "min_abs_x = coef_series.abs().sort_values().index[0]\n",
    "\n",
    "print \"\\nAvg Accuracy : {}\".format(accuracy_arr[i])\n",
    "print \"\\nMin Predictor: {}\".format(min_abs_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Beta:\n",
      "markov           0.685882\n",
      "rpi              0.539828\n",
      "momentum         0.243739\n",
      "off_eff          0.212124\n",
      "def_eff         -0.212024\n",
      "weighted_wins   -0.214893\n",
      "bad_losses      -0.312466\n",
      "dtype: float64\n",
      "\n",
      "Avg Accuracy : 0.690476190476\n",
      "\n",
      "Min Predictor: def_eff\n"
     ]
    }
   ],
   "source": [
    "variables.remove(min_abs_x)\n",
    "i = 11\n",
    "\n",
    "# print with current set of variables\n",
    "accuracy_arr[i], coef_series = run_logistic_model(train_test_arr, variables)\n",
    "\n",
    "# minimum absolute value beta\n",
    "min_abs_x = coef_series.abs().sort_values().index[0]\n",
    "\n",
    "print \"\\nAvg Accuracy : {}\".format(accuracy_arr[i])\n",
    "print \"\\nMin Predictor: {}\".format(min_abs_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Beta:\n",
      "markov           0.918705\n",
      "rpi              0.496722\n",
      "momentum         0.237007\n",
      "off_eff          0.076667\n",
      "weighted_wins   -0.268042\n",
      "bad_losses      -0.349951\n",
      "dtype: float64\n",
      "\n",
      "Avg Accuracy : 0.690476190476\n",
      "\n",
      "Min Predictor: off_eff\n"
     ]
    }
   ],
   "source": [
    "variables.remove(min_abs_x)\n",
    "i = 12\n",
    "\n",
    "# print with current set of variables\n",
    "accuracy_arr[i], coef_series = run_logistic_model(train_test_arr, variables)\n",
    "\n",
    "# minimum absolute value beta\n",
    "min_abs_x = coef_series.abs().sort_values().index[0]\n",
    "\n",
    "print \"\\nAvg Accuracy : {}\".format(accuracy_arr[i])\n",
    "print \"\\nMin Predictor: {}\".format(min_abs_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Beta:\n",
      "markov           0.960648\n",
      "rpi              0.474713\n",
      "momentum         0.219379\n",
      "weighted_wins   -0.248433\n",
      "bad_losses      -0.367529\n",
      "dtype: float64\n",
      "\n",
      "Avg Accuracy : 0.698412698413\n",
      "\n",
      "Min Predictor: momentum\n"
     ]
    }
   ],
   "source": [
    "variables.remove(min_abs_x)\n",
    "i = 13\n",
    "\n",
    "# print with current set of variables\n",
    "accuracy_arr[i], coef_series = run_logistic_model(train_test_arr, variables)\n",
    "\n",
    "# minimum absolute value beta\n",
    "min_abs_x = coef_series.abs().sort_values().index[0]\n",
    "\n",
    "print \"\\nAvg Accuracy : {}\".format(accuracy_arr[i])\n",
    "print \"\\nMin Predictor: {}\".format(min_abs_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Beta:\n",
      "markov           1.062516\n",
      "rpi              0.532616\n",
      "weighted_wins   -0.210669\n",
      "bad_losses      -0.332528\n",
      "dtype: float64\n",
      "\n",
      "Avg Accuracy : 0.708333333333\n",
      "\n",
      "Min Predictor: weighted_wins\n"
     ]
    }
   ],
   "source": [
    "variables.remove(min_abs_x)\n",
    "i = 14\n",
    "\n",
    "# print with current set of variables\n",
    "accuracy_arr[i], coef_series = run_logistic_model(train_test_arr, variables)\n",
    "\n",
    "# minimum absolute value beta\n",
    "min_abs_x = coef_series.abs().sort_values().index[0]\n",
    "\n",
    "print \"\\nAvg Accuracy : {}\".format(accuracy_arr[i])\n",
    "print \"\\nMin Predictor: {}\".format(min_abs_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Beta:\n",
      "markov        0.982989\n",
      "rpi           0.391584\n",
      "bad_losses   -0.359787\n",
      "dtype: float64\n",
      "\n",
      "Avg Accuracy : 0.714285714286\n",
      "\n",
      "Min Predictor: bad_losses\n"
     ]
    }
   ],
   "source": [
    "variables.remove(min_abs_x)\n",
    "i = 15\n",
    "\n",
    "# print with current set of variables\n",
    "accuracy_arr[i], coef_series = run_logistic_model(train_test_arr, variables)\n",
    "\n",
    "# minimum absolute value beta\n",
    "min_abs_x = coef_series.abs().sort_values().index[0]\n",
    "\n",
    "print \"\\nAvg Accuracy : {}\".format(accuracy_arr[i])\n",
    "print \"\\nMin Predictor: {}\".format(min_abs_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Beta:\n",
      "markov    1.046127\n",
      "rpi       0.608434\n",
      "dtype: float64\n",
      "\n",
      "Avg Accuracy : 0.708333333333\n",
      "\n",
      "Min Predictor: rpi\n"
     ]
    }
   ],
   "source": [
    "variables.remove(min_abs_x)\n",
    "i = 16\n",
    "\n",
    "# print with current set of variables\n",
    "accuracy_arr[i], coef_series = run_logistic_model(train_test_arr, variables)\n",
    "\n",
    "# minimum absolute value beta\n",
    "min_abs_x = coef_series.abs().sort_values().index[0]\n",
    "\n",
    "print \"\\nAvg Accuracy : {}\".format(accuracy_arr[i])\n",
    "print \"\\nMin Predictor: {}\".format(min_abs_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Beta:\n",
      "markov    1.526167\n",
      "dtype: float64\n",
      "\n",
      "Avg Accuracy : 0.710317460317\n",
      "\n",
      "Min Predictor: markov\n"
     ]
    }
   ],
   "source": [
    "variables.remove(min_abs_x)\n",
    "i = 17\n",
    "\n",
    "# print with current set of variables\n",
    "accuracy_arr[i], coef_series = run_logistic_model(train_test_arr, variables)\n",
    "\n",
    "# minimum absolute value beta\n",
    "min_abs_x = coef_series.abs().sort_values().index[0]\n",
    "\n",
    "print \"\\nAvg Accuracy : {}\".format(accuracy_arr[i])\n",
    "print \"\\nMin Predictor: {}\".format(min_abs_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a maximum when there is 10 variables, but this is essentially the same as having only 3 variables in our model. As such, we will use the model that has 3 variables, which are markov, rpi, and bad losses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Beta:\n",
      "markov             0.180721\n",
      "rpi                0.164619\n",
      "win ratio          0.110281\n",
      "momentum           0.097683\n",
      "bad_losses         0.075358\n",
      "weighted_wins      0.056131\n",
      "luck               0.051845\n",
      "wins               0.041618\n",
      "tough_wins         0.038232\n",
      "dominance          0.037921\n",
      "off_eff            0.032098\n",
      "consistency        0.025604\n",
      "losses             0.021562\n",
      "def_eff            0.019752\n",
      "tempo              0.018909\n",
      "past_resul         0.018153\n",
      "close_wins_perc    0.005282\n",
      "close_wins         0.004232\n",
      "dtype: float64\n",
      "\n",
      "Avg Accuracy : 0.690476190476\n",
      "\n",
      "Min Predictor: markov\n"
     ]
    }
   ],
   "source": [
    "# list of the variables we care about\n",
    "variables = predictor_names[2:]\n",
    "\n",
    "# print with current set of variables\n",
    "accuracy_rf, importances_series = run_random_forest_model(train_test_arr, variables)\n",
    "\n",
    "# minimum absolute value beta\n",
    "min_abs_x = coef_series.abs().sort_values().index[0]\n",
    "\n",
    "print \"\\nAvg Accuracy : {}\".format(accuracy_rf)\n",
    "print \"\\nMin Predictor: {}\".format(min_abs_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'march_madness_train_and_tune' from 'march_madness_train_and_tune.py'>"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(mmtt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_test_arr_score_x = []\n",
    "\n",
    "window   = 3\n",
    "min_year = 2006\n",
    "max_year = 2014\n",
    "\n",
    "year_range = range(min_year, max_year)\n",
    "\n",
    "# generate our train test split for each year\n",
    "for year in year_range:\n",
    "    # do the split for the current year\n",
    "    train_test_tuple = mmtt.train_test_split(window, \n",
    "                                             year, \n",
    "                                             seeds_arr, \n",
    "                                             slots_arr, \n",
    "                                             games_arr, \n",
    "                                             predictor_names, \n",
    "                                             predictor_dfs,\n",
    "                                             scoring_dif=True)\n",
    "    \n",
    "    # add to our array\n",
    "    train_test_arr_score_x.append(train_test_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max r2 of 0.38371122671 with Alpha = 1\n"
     ]
    }
   ],
   "source": [
    "# cross validate the lambda\n",
    "alpha_arr = range(-7, 8)\n",
    "r2_scores = np.zeros(len(alpha_arr))\n",
    "\n",
    "i = 0\n",
    "for alpha in alpha_arr:\n",
    "    # un lasso, get r2\n",
    "    r2_scores[i], x = run_lasso_model(train_test_arr_score_x, variables, 10**alpha, print_res=False)\n",
    "    \n",
    "    i = i + 1\n",
    "\n",
    "max_score = r2_scores.max()\n",
    "max_index = r2_scores.argmax()\n",
    "\n",
    "print \"Max r2 of {} with Alpha = {}\".format(max_score, 10**range(-7,8)[max_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Beta:\n",
      "rpi                3.547760\n",
      "markov             3.275812\n",
      "win ratio          0.946130\n",
      "momentum           0.532639\n",
      "past_resul         0.111317\n",
      "dominance          0.070944\n",
      "off_eff            0.039211\n",
      "close_wins         0.000000\n",
      "weighted_wins      0.000000\n",
      "tough_wins         0.000000\n",
      "luck               0.000000\n",
      "losses             0.000000\n",
      "def_eff            0.000000\n",
      "tempo              0.000000\n",
      "wins               0.000000\n",
      "close_wins_perc    0.000000\n",
      "consistency       -0.100189\n",
      "bad_losses        -0.543115\n",
      "dtype: float64\n",
      "\n",
      "Avg R2 : 0.383706635824\n"
     ]
    }
   ],
   "source": [
    "# list of the variables we care about\n",
    "variables = predictor_names[2:]\n",
    "\n",
    "# print with current set of variables\n",
    "r2_lasso, importances_series = run_lasso_model(train_test_arr_score_x, variables, 1, print_res=True)\n",
    "\n",
    "# minimum absolute value beta\n",
    "min_abs_x = coef_series.abs().sort_values().index[0]\n",
    "\n",
    "print \"\\nAvg R2 : {}\".format(r2_lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso Regression identifies the important variables for predicting the score of the games. We fit a logistic model on these variables (with nonzero coefficients) and compare it to our other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "variables = [\"rpi\", \"markov\", \"win ratio\", \"momentum\", \"past_resul\", \"dominance\", \"off_eff\", \"consistency\", \"bad_losses\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Beta:\n",
      "markov         0.636353\n",
      "rpi            0.435175\n",
      "win ratio      0.335957\n",
      "momentum       0.216902\n",
      "dominance      0.050811\n",
      "off_eff        0.043199\n",
      "consistency    0.035364\n",
      "past_resul    -0.125404\n",
      "bad_losses    -0.360872\n",
      "dtype: float64\n",
      "\n",
      "Avg Accuracy : 0.714285714286\n"
     ]
    }
   ],
   "source": [
    "# print with current set of variables\n",
    "accuracy_log_reg_lasso_vars, coef_series = run_logistic_model(train_test_arr, variables)\n",
    "\n",
    "print \"\\nAvg Accuracy : {}\".format(accuracy_arr[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x122cd4c10>"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4MAAAFRCAYAAADO/nj3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJEmSSsgyKEmSJEklZBmUJEmSpBL6/6vB6kl9axcxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x121b8f310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10,5))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot([0, 18], [accuracy_rf, accuracy_rf], color=\"b\", label=\"random_forest\", lw=1.5)\n",
    "ax.plot([0, 18], [accuracy_log_reg_lasso_vars, accuracy_log_reg_lasso_vars], color=\"r\", label=\"logistic with lasso var selection\", lw=1.5)\n",
    "ax.plot(range(1, 19), accuracy_arr[::-1], color=\"g\", label=\"logistic with step wise var selection\", lw=1.5)\n",
    "ax.set_xlim([1,18])\n",
    "ax.set_ylim([.65,.75])\n",
    "ax.set_xlabel(\"Number of Variables\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.set_title(\"Accuracies of Various Models on Test Sets\")\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 4) Cross Validate Regularization Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cross validate for all 3 logistic models \n",
    "c_values = [.0001, .001, .01, .1, 1, 10, 100, 1000, 100000]\n",
    "scores_10_var = np.zeros(len(c_values))\n",
    "scores_3_var = np.zeros(len(c_values))\n",
    "scores_lasso_vars = np.zeros(len(c_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# variables\n",
    "variables_3 = [\"markov\", \"rpi\", \"bad_losses\"]\n",
    "variables_10 = [\"markov\", \"rpi\", \"momentum\", \"off_eff\", \"tempo\", \"close_wins\", \"past_resul\", \"def_eff\", \"weighted_wins\",\"bad_losses\"]\n",
    "variables_lasso = [\"rpi\", \"markov\", \"win ratio\", \"momentum\", \"past_resul\", \"dominance\", \"off_eff\", \"consistency\", \"bad_losses\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cross validate function\n",
    "def cv_c_value(train_test_arr, variables, c_values):\n",
    "    scores = np.zeros(len(c_values))\n",
    "    \n",
    "    i = 0\n",
    "    for c_val in c_values:\n",
    "        # print with current set of variables\n",
    "        scores[i], x = run_logistic_model(train_test_arr, variables, c=c_val, print_res=False)\n",
    "        \n",
    "        i = i + 1 \n",
    "        \n",
    "    max_score = scores.max()\n",
    "    max_score_ind = scores.argmax()\n",
    "    \n",
    "    print \"Max Accuracy of {} with C = {}\".format(max_score, c_values[max_score_ind])\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Accuracy of 0.718253968254 with C = 0.0001\n"
     ]
    }
   ],
   "source": [
    "# cv for 3 variables\n",
    "scores_3 = cv_c_value(train_test_arr, variables_3, c_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Accuracy of 0.71626984127 with C = 1\n"
     ]
    }
   ],
   "source": [
    "# cv for 10 variables\n",
    "scores_10 = cv_c_value(train_test_arr, variables_10, c_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Accuracy of 0.706349206349 with C = 0.1\n"
     ]
    }
   ],
   "source": [
    "# cv for lasso variables\n",
    "scores_lasso = cv_c_value(train_test_arr, variables_lasso, c_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x12541a290>"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxAAAAFRCAYAAADkYksdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x124e75ad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10,5))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(c_values, scores_3, label=\"3 variables\", color=\"g\", lw=1.5)\n",
    "ax.plot(c_values, scores_10, label=\"10 variables\", color=\"r\", lw=1.5)\n",
    "ax.plot(c_values, scores_lasso, label=\"Lasso variables\", color=\"b\", lw=1.5)\n",
    "ax.set_ylim([.69,.72])\n",
    "ax.set_xlabel(\"Regularization Strength Inv\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.set_title(\"Accuracies as a function of C\")\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As such, we will use the 3 variable model with C=1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
